{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d066083b",
   "metadata": {},
   "source": [
    "# Constructive Heuristic Template\n",
    "# Type here the Name of the Combinatorial problem you studied\n",
    "Prof. María Angélica Salazar Aguilar\n",
    "\n",
    "Selected Topics of Optimization\n",
    "\n",
    "---\n",
    "This notebook is a template for documenting a combinatorial optimization problem and its constructive heuristic. Follow the instructions in each section and provide the required content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfb366",
   "metadata": {},
   "source": [
    "## 1. Team: TeamID\n",
    "\n",
    "Provide the names, student IDs, and contact information of all team members below.\n",
    "\n",
    "|Student ID      | Name  | Email             |\n",
    "|----------------|------------|-------------------|\n",
    "|2013939         | Aldo Sebastian Lopez Rivas | aldo.lopezrvs@uanl.edu.mx                  |\n",
    "|2173850                |Josue Sebastian Cruz Cantu            |            josue.cruzcn@uanl.edu.mx       |\n",
    "|2173891                |Iver Jair Salas Sanchez            |     iver.salass@uanl.edu.mx              |\n",
    "|2014777                |Juan Carlos Sanchez Valencia|        juan.sanchezvln@uanl.edu.mx           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5100e",
   "metadata": {},
   "source": [
    "## 2. General Description of the Problem\n",
    "\n",
    "Flow Shop Scheduling Problem (FSSP) schedules n jobs on m machines in the same order on all machines, minimizing an objective such as makespan (Cmax). Applications include manufacturing lines, semiconductor fabrication, and any staged processing systems with identical routing per job. The problem is NP-hard for m ≥ 3, motivating heuristics for high-quality solutions quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5eceff",
   "metadata": {},
   "source": [
    "## 3. Mathematical Formulation\n",
    "\n",
    "**Flow Shop Scheduling Problem (FSSP)**\n",
    "\n",
    "**Sets and data**  \n",
    "- $J=\\{1,\\dots,n\\}$ jobs, $M=\\{1,\\dots,m\\}$ machines.  \n",
    "- $p_{ij}\\ge 0$: processing time of job $j$ on machine $i$.  \n",
    "- A permutation (sequence) of jobs is denoted by $\\pi=(\\pi_1,\\ldots,\\pi_n)$.\n",
    "\n",
    "**State (completion-time) recursions**  \n",
    "Let $C_{i,\\pi_k}$ be the completion time of job $\\pi_k$ on machine $i$. Then\n",
    "\n",
    "\\begin{align}\n",
    "C_{1,\\pi_1} &= p_{1,\\pi_1}, \\\\\n",
    "C_{1,\\pi_k} &= C_{1,\\pi_{k-1}} + p_{1,\\pi_k} \\qquad (k=2,\\ldots,n), \\\\\n",
    "C_{i,\\pi_1} &= C_{i-1,\\pi_1} + p_{i,\\pi_1} \\qquad (i=2,\\ldots,m), \\\\\n",
    "C_{i,\\pi_k} &= \\max\\{\\, C_{i-1,\\pi_k},\\; C_{i,\\pi_{k-1}} \\,\\} + p_{i,\\pi_k} \\qquad (i=2,\\ldots,m;\\; k=2,\\ldots,n).\n",
    "\\end{align}\n",
    "\n",
    "The **makespan** is $C_{\\max} = C_{m,\\pi_n}$.\n",
    "\n",
    "**Objective**  \n",
    "$$\n",
    "\\min_{\\pi \\in \\mathcal{S}_n} \\; C_{\\max}(\\pi) \\;=\\; C_{m,\\pi_n}.\n",
    "$$\n",
    "\n",
    "where $\\mathcal{S}_n$ is the set of all permutations of $n$ jobs (identical machine order for every job).\n",
    "\n",
    "> *Note.* A full MILP can be written with binary assignment variables $x_{jk}\\in\\{0,1\\}$ indicating job $j$ at position $k$ and time variables, but here we emphasize a constructive permutation heuristic.\n",
    "\n",
    "---\n",
    "\n",
    "### Pendulum Heuristic (used to construct $\\pi$)\n",
    "\n",
    "**Idea.** Sort jobs by total processing time $T_j=\\sum_{i=1}^m p_{ij}$ (ascending) and place them alternately at the left and right ends of the sequence so that small totals go to the extremes and large totals concentrate toward the center.\n",
    "\n",
    "**Steps**\n",
    "1. Compute $T_j=\\sum_{i=1}^m p_{ij}$ for all $j\\in J$.\n",
    "2. Let $(j_1,\\ldots,j_n)$ be the order of jobs such that $T_{j_1}\\le \\cdots \\le T_{j_n}$.  \n",
    "3. Initialize two pointers $l\\leftarrow 1$, $r\\leftarrow n$. For $k=1$ to $n$:\n",
    "   - if $k$ is odd, set $\\pi_l \\leftarrow j_k$ and $l\\leftarrow l+1$;\n",
    "   - if $k$ is even, set $\\pi_r \\leftarrow j_k$ and $r\\leftarrow r-1$.\n",
    "\n",
    "This yields a permutation $\\pi$ with lighter jobs at the ends and heavier jobs near the center (a “pendulum” layout).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c3e91",
   "metadata": {},
   "source": [
    "## 4. Pseudocode of the Proposed Constructive Heuristic\n",
    "\n",
    "```\n",
    "\n",
    "Input:\n",
    "  processing_times  // m x n matrix, processing_times[i][j] ≥ 0\n",
    "\n",
    "Initialize solution\n",
    "  if processing_times is empty:\n",
    "      return []\n",
    "  n ← number of jobs (number of columns)\n",
    "  // compute job totals\n",
    "  T[0..n-1] ← array\n",
    "  for j from 0 to n-1:\n",
    "      T[j] ← 0\n",
    "      for i from 0 to m-1:\n",
    "          T[j] ← T[j] + processing_times[i][j]\n",
    "  // order jobs by ascending totals\n",
    "  L ← list of job indices 0..n-1 sorted by T[j] ascending\n",
    "  π[0..n-1] ← empty array\n",
    "  left  ← 0\n",
    "  right ← n - 1\n",
    "  k ← 0\n",
    "\n",
    "While [k < n]:\n",
    "    Select next element according to heuristic\n",
    "        job ← L[k]                       // kth smallest by total time\n",
    "    Update solution\n",
    "        if (k mod 2) == 0:\n",
    "            π[left]  ← job\n",
    "            left ← left + 1\n",
    "        else:\n",
    "            π[right] ← job\n",
    "            right ← right - 1\n",
    "        k ← k + 1\n",
    "\n",
    "Output:\n",
    "  π  // permutation with small-total jobs at the extremes and large totals near the center\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb99d74",
   "metadata": {},
   "source": [
    "## 5. Description and Definition of Main Functions\n",
    "\n",
    "Below are the core functions used in our solver. The **Pendulum heuristic** is the primary constructor; other heuristics are included only for comparison.\n",
    "\n",
    "---\n",
    "\n",
    "### `read_csv_data(file_path) -> (processing_times, job_names)`  \n",
    "*Module:* `io_utils`  \n",
    "- **Purpose:** Load the instance from CSV with light auto-detection (headers, sizes) and validation of values.  \n",
    "- **Inputs:** Path to CSV.  \n",
    "- **Outputs:** `processing_times` (list of jobs × machines), `job_names` (list of strings).\n",
    "\n",
    "---\n",
    "\n",
    "### `validate_processing_times(processing_times) -> bool`  \n",
    "*Module:* `io_utils`  \n",
    "- **Purpose:** Sanity-check the matrix (dimensions consistent, non-negative numbers, correct types).  \n",
    "- **Inputs:** Processing-time matrix.  \n",
    "- **Outputs:** `True` or raises a descriptive `ValueError`.\n",
    "\n",
    "---\n",
    "\n",
    "### `pendulum_heuristic(processing_times) -> sequence` *(main constructive heuristic)*  \n",
    "*Module:* `heuristics`  \n",
    "- **Purpose:** Build a permutation by sorting jobs by total time (ascending) and placing them alternately at the left and right ends so small totals go to the extremes and large totals gravitate to the center.  \n",
    "- **Inputs:** Processing-time matrix.  \n",
    "- **Outputs:** `sequence` (list of job indices, 0-based).\n",
    "\n",
    "---\n",
    "\n",
    "### `calculate_makespan(processing_times, sequence) -> float`  \n",
    "*Module:* `makespan`  \n",
    "- **Purpose:** Evaluate a sequence using the standard flow-shop completion-time recursion; returns the completion time of the last job on the last machine.  \n",
    "- **Inputs:** Processing-time matrix, permutation.  \n",
    "- **Outputs:** `makespan` (float).\n",
    "\n",
    "---\n",
    "\n",
    "### `print_sequence_analysis(processing_times, sequence, job_names=None) -> None`  \n",
    "*Module:* `makespan`  \n",
    "- **Purpose:** Convenience reporter: prints makespan, per-machine idle times, and utilization/efficiency for a given sequence.  \n",
    "- **Inputs:** Matrix, permutation, optional job names.  \n",
    "- **Outputs:** Console report (no return).\n",
    "\n",
    "---\n",
    "\n",
    "### `(utility for demos) create_sample_data(file_path, num_jobs=5, num_machines=3) -> None`  \n",
    "*Module:* `main`  \n",
    "- **Purpose:** Generate a small synthetic instance for testing and demos.  \n",
    "- **Inputs:** Output path, numbers of jobs/machines.  \n",
    "- **Outputs:** CSV file written to disk.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note:** Additional constructive heuristics (NEH, SPT/LPT, Palmer, CDS/Johnson) are implemented to enable fair comparisons but are not the primary focus of this study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d60fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Implementation of the Constructive Heuristic\n",
    "\n",
    "def read_csv_data(file_path: str) -> Tuple[List[List[float]], List[str]]:\n",
    "    \"\"\"\n",
    "    Read CSV file and return processing times matrix and job names.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[List[float]], List[str]]: (processing_times, job_names)\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If file doesn't exist\n",
    "        ValueError: If data format is invalid\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found: {file_path}\")\n",
    "        \n",
    "    try:\n",
    "        has_headers, num_jobs, num_machines = detect_csv_format(file_path)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path, header=0 if has_headers else None)\n",
    "        \n",
    "        # Generate job names\n",
    "        if has_headers:\n",
    "            job_names = [f\"Job_{i+1}\" for i in range(num_jobs)]\n",
    "        else:\n",
    "            job_names = [f\"Job_{i+1}\" for i in range(len(df))]\n",
    "            \n",
    "        # Extract processing times\n",
    "        processing_times = []\n",
    "        for _, row in df.iterrows():\n",
    "            # Convert row to list of floats, filtering out empty values\n",
    "            times = []\n",
    "            for value in row:\n",
    "                if pd.notna(value) and str(value).strip():\n",
    "                    try:\n",
    "                        times.append(float(value))\n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "            if times:  # Only add non-empty rows\n",
    "                processing_times.append(times)\n",
    "                \n",
    "        # Validate data consistency\n",
    "        if not processing_times:\n",
    "            raise ValueError(\"No valid processing time data found in CSV\")\n",
    "            \n",
    "        # Check that all jobs have the same number of machines\n",
    "        machine_counts = [len(job) for job in processing_times]\n",
    "        if len(set(machine_counts)) > 1:\n",
    "            raise ValueError(f\"Inconsistent number of machines per job: {set(machine_counts)}\")\n",
    "            \n",
    "        # Ensure non-negative processing times\n",
    "        for i, job_times in enumerate(processing_times):\n",
    "            for j, time in enumerate(job_times):\n",
    "                if time < 0:\n",
    "                    raise ValueError(f\"Negative processing time found at Job {i+1}, Machine {j+1}: {time}\")\n",
    "                    \n",
    "        return processing_times, job_names[:len(processing_times)]\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"CSV file is empty\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        raise ValueError(f\"Error parsing CSV file: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading CSV data: {str(e)}\")\n",
    "\n",
    "def validate_processing_times(processing_times: List[List[float]]) -> bool:\n",
    "    \"\"\"\n",
    "    Validate the processing times matrix for logical consistency.\n",
    "    \n",
    "    Args:\n",
    "        processing_times (List[List[float]]): Matrix of processing times\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if valid, raises ValueError if invalid\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If data is logically inconsistent\n",
    "    \"\"\"\n",
    "    if not processing_times:\n",
    "        raise ValueError(\"Processing times matrix is empty\")\n",
    "        \n",
    "    if not all(isinstance(job, list) for job in processing_times):\n",
    "        raise ValueError(\"Processing times must be a list of lists\")\n",
    "        \n",
    "    # Check dimensions consistency\n",
    "    num_machines = len(processing_times[0])\n",
    "    for i, job_times in enumerate(processing_times):\n",
    "        if len(job_times) != num_machines:\n",
    "            raise ValueError(f\"Job {i+1} has {len(job_times)} machines, expected {num_machines}\")\n",
    "            \n",
    "    # Check for non-negative values\n",
    "    for i, job_times in enumerate(processing_times):\n",
    "        for j, time in enumerate(job_times):\n",
    "            if not isinstance(time, (int, float)) or time < 0:\n",
    "                raise ValueError(f\"Invalid processing time at Job {i+1}, Machine {j+1}: {time}\")\n",
    "                \n",
    "    return True\n",
    "\n",
    "def pendulum_heuristic(processing_times: List[List[float]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Pendulum heuristic: place jobs with smaller total times at extremes,\n",
    "    larger total times in the center (like a pendulum weight distribution).\n",
    "    \n",
    "    Args:\n",
    "        processing_times (List[List[float]]): Matrix of processing times\n",
    "        \n",
    "    Returns:\n",
    "        List[int]: Sequence following pendulum pattern\n",
    "    \"\"\"\n",
    "    if not processing_times:\n",
    "        return []\n",
    "    \n",
    "    num_jobs = len(processing_times)\n",
    "    \n",
    "    # Calculate total processing time for each job and sort ascending\n",
    "    job_totals = [(i, calculate_total_processing_time(processing_times, i)) \n",
    "                  for i in range(num_jobs)]\n",
    "    job_totals.sort(key=lambda x: x[1])  # Sort by total time (ascending)\n",
    "    sorted_jobs = [job[0] for job in job_totals]\n",
    "    \n",
    "    # Build pendulum sequence: small jobs at ends, big jobs in center\n",
    "    sequence = [0] * num_jobs\n",
    "    left = 0\n",
    "    right = num_jobs - 1\n",
    "    \n",
    "    # Place jobs alternating from extremes toward center\n",
    "    for i, job_idx in enumerate(sorted_jobs):\n",
    "        if i % 2 == 0:  # Even indices: place at left extreme, move inward\n",
    "            sequence[left] = job_idx\n",
    "            left += 1\n",
    "        else:  # Odd indices: place at right extreme, move inward\n",
    "            sequence[right] = job_idx\n",
    "            right -= 1\n",
    "    \n",
    "    return sequence\n",
    "\n",
    "def calculate_makespan(processing_times: List[List[float]], sequence: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the makespan for a given job sequence in a flow shop.\n",
    "    \n",
    "    The makespan is the total time required to complete all jobs, which is\n",
    "    determined by the completion time of the last job on the last machine.\n",
    "    \n",
    "    Args:\n",
    "        processing_times (List[List[float]]): Matrix where processing_times[i][j] \n",
    "                                            represents the processing time of job i on machine j\n",
    "        sequence (List[int]): Sequence of job indices (0-based)\n",
    "        \n",
    "    Returns:\n",
    "        float: The makespan (total completion time)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If sequence contains invalid job indices\n",
    "    \"\"\"\n",
    "    if not processing_times or not sequence:\n",
    "        return 0.0\n",
    "        \n",
    "    num_jobs = len(processing_times)\n",
    "    num_machines = len(processing_times[0])\n",
    "    \n",
    "    # Validate sequence\n",
    "    for job_idx in sequence:\n",
    "        if job_idx < 0 or job_idx >= num_jobs:\n",
    "            raise ValueError(f\"Invalid job index {job_idx}. Must be between 0 and {num_jobs-1}\")\n",
    "    \n",
    "    # Initialize completion time matrix\n",
    "    # completion_times[i][j] = completion time of job i on machine j\n",
    "    completion_times = [[0.0 for _ in range(num_machines)] for _ in range(len(sequence))]\n",
    "    \n",
    "    # Calculate completion times for each job in the sequence\n",
    "    for seq_pos, job_idx in enumerate(sequence):\n",
    "        for machine in range(num_machines):\n",
    "            # Processing time for current job on current machine\n",
    "            proc_time = processing_times[job_idx][machine]\n",
    "            \n",
    "            if seq_pos == 0 and machine == 0:\n",
    "                # First job on first machine\n",
    "                completion_times[seq_pos][machine] = proc_time\n",
    "            elif seq_pos == 0:\n",
    "                # First job on subsequent machines\n",
    "                completion_times[seq_pos][machine] = (\n",
    "                    completion_times[seq_pos][machine - 1] + proc_time\n",
    "                )\n",
    "            elif machine == 0:\n",
    "                # Subsequent jobs on first machine\n",
    "                completion_times[seq_pos][machine] = (\n",
    "                    completion_times[seq_pos - 1][machine] + proc_time\n",
    "                )\n",
    "            else:\n",
    "                # Subsequent jobs on subsequent machines\n",
    "                completion_times[seq_pos][machine] = (\n",
    "                    max(completion_times[seq_pos - 1][machine],\n",
    "                        completion_times[seq_pos][machine - 1]) + proc_time\n",
    "                )\n",
    "    \n",
    "    # Makespan is the completion time of the last job on the last machine\n",
    "    return completion_times[-1][-1]\n",
    "\n",
    "def print_sequence_analysis(processing_times: List[List[float]], \n",
    "                          sequence: List[int], \n",
    "                          job_names: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Print detailed analysis of a job sequence.\n",
    "    \n",
    "    Args:\n",
    "        processing_times (List[List[float]]): Matrix of processing times\n",
    "        sequence (List[int]): Sequence of job indices\n",
    "        job_names (List[str], optional): Names of jobs for display\n",
    "    \"\"\"\n",
    "    if job_names is None:\n",
    "        job_names = [f\"Job_{i+1}\" for i in range(len(processing_times))]\n",
    "    \n",
    "    metrics = evaluate_sequence_quality(processing_times, sequence)\n",
    "    \n",
    "    print(f\"\\n=== Sequence Analysis ===\")\n",
    "    print(f\"Job sequence: {' -> '.join([job_names[i] for i in sequence])}\")\n",
    "    print(f\"Makespan: {metrics['makespan']:.2f}\")\n",
    "    print(f\"Total idle time: {metrics['total_idle_time']:.2f}\")\n",
    "    print(f\"Machine utilization: {metrics['utilization']:.2%}\")\n",
    "    print(f\"Overall efficiency: {metrics['efficiency']:.2%}\")\n",
    "    \n",
    "    print(f\"\\nMachine idle times:\")\n",
    "    for i, idle_time in enumerate(metrics['machine_idle_times']):\n",
    "        print(f\"  Machine {i+1}: {idle_time:.2f}\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233cd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Main Function to Run the Code\n",
    "\n",
    "def solve_flow_shop(csv_file_path: str, \n",
    "                   verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Main function to solve Flow Shop Scheduling Problem.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path (str): Path to CSV file containing processing times\n",
    "        verbose (bool): Whether to print detailed output\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results containing best sequence, makespan, and other metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Read and validate input data\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"FLOW SHOP SCHEDULING PROBLEM SOLVER\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Reading data from: {csv_file_path}\")\n",
    "        \n",
    "        processing_times, job_names = read_csv_data(csv_file_path)\n",
    "        validate_processing_times(processing_times)\n",
    "        \n",
    "        if verbose:\n",
    "            print_data_summary(processing_times, job_names)\n",
    "        \n",
    "        # Step 2: Apply Pendulum heuristic for main solution\n",
    "        if verbose:\n",
    "            print(\"\\nApplying Pendulum heuristic for main solution...\")\n",
    "        \n",
    "        pendulum_sequence = pendulum_heuristic(processing_times)\n",
    "        pendulum_makespan = calculate_makespan(processing_times, pendulum_sequence)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Pendulum Heuristic Result:\")\n",
    "            print(f\"  Sequence: {' -> '.join([job_names[i] for i in pendulum_sequence])}\")\n",
    "            print(f\"  Makespan: {pendulum_makespan:.2f}\")\n",
    "        \n",
    "        # Step 3: Compare different heuristics\n",
    "        if verbose:\n",
    "            print_heuristic_comparison(processing_times, job_names)\n",
    "        \n",
    "        # Step 4: Final results (Pendulum is the main sequence)\n",
    "        best_sequence = pendulum_sequence\n",
    "        best_makespan = pendulum_makespan\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"FINAL RESULTS\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Best sequence: {' -> '.join([job_names[i] for i in best_sequence])}\")\n",
    "            print(f\"Best makespan: {best_makespan:.2f}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Detailed analysis of best sequence\n",
    "            print_sequence_analysis(processing_times, best_sequence, job_names)\n",
    "        \n",
    "        # Return results for programmatic use\n",
    "        return {\n",
    "            'best_sequence': best_sequence,\n",
    "            'best_makespan': best_makespan,\n",
    "            'job_names': job_names,\n",
    "            'processing_times': processing_times,\n",
    "            'pendulum_sequence': pendulum_sequence,\n",
    "            'pendulum_makespan': pendulum_makespan\n",
    "        }\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Data validation error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c974408",
   "metadata": {},
   "source": [
    "## 8. Computational Results and Discussion\n",
    "(https://github.com/chneau/go-taillard/tree/master/pfsp/instances)\n",
    "\n",
    "\n",
    "| Instance | Objective Value Heuristic | Objective Value (Optimal) | Gap (%) |\n",
    "|----------|----------|----------------|----------|\n",
    "|     1     |    1941      |      1582          |     22.7%     |\n",
    "|     2     |     2020     |        1659        |       21.76%   |\n",
    "|     3     |      2026    |          1496      |     35.43%     |\n",
    "|     4     |      2590    |         2297       |     12.8%     |\n",
    "|     5     |      2647    |         2100       |     26.1%     |\n",
    "|     6     |      2803    |        2326        |     20.51%     |\n",
    "|     7     |      3785    |        3025        |      25.1%    |\n",
    "|     8     |     3474     |         2892       |     20.1%     |\n",
    "|     9     |      3953    |        2864        |     38%     |\n",
    "|    10     |      6744    |        5770        |      16.9%    |\n",
    "|    11     |      6434    |        5349        |     20.3%     |\n",
    "|    12     |      6700    |       5677         |    18%      |\n",
    "|    13     |      7862    |        6286        |     25.1%     |\n",
    "|    14     |      7759    |      6241          |    24.32%      |\n",
    "|    15     |      7827    |        6329        |     23.7%     |\n",
    "\n",
    "**Discussion:**\n",
    "- Regarding the effectiveness of the heuristic, the results show an average gap of about 23%, with some instances reaching as low as 12.8%. This indicates a reasonably consistent performance, though the method still leaves a notable margin from the optimal.\n",
    "\n",
    "- When comparing across instances, no clear trend of deterioration with problem size is observed, which suggests good scalability. Outliers such as instances 3 and 9, however, highlight situations where the heuristic struggles, and including computation times would help balance quality against efficiency.\n",
    "\n",
    "- In terms of patterns, most results fall within the 20–25% gap range, with only a few extreme cases. This points to a stable baseline that could be improved by adding local refinement or multi-start strategies to reduce the worst gaps and bring the average closer to competitive levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd5779",
   "metadata": {},
   "source": [
    "## 9. General Conclusions\n",
    "\n",
    "The heuristic developed in this work was intentionally kept simple and implemented relatively quickly during class. While it provides feasible solutions with an average gap of around 23%, its performance was slightly worse than initially expected. Part of this can be attributed to missing logic that was overlooked during implementation, which limited the quality of the results.\n",
    "\n",
    "A key lesson learned is that even a basic heuristic can provide consistent approximations, but careful design choices and refinement are crucial to avoid systematic weaknesses. The analysis also highlighted the importance of testing across diverse instances, since a few outliers revealed specific scenarios where the method struggles.\n",
    "\n",
    "For future work, there are several straightforward improvements that could be explored, such as adding local search steps, introducing randomized restarts, or refining the construction logic. These additions are expected to reduce the gap significantly and would serve as natural next steps if the goal were to turn this initial prototype into a more competitive approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda0923",
   "metadata": {},
   "source": [
    "## 10. Revised References\n",
    "\n",
    "- Chneau, C. (n.d.). go-taillard: PFSP instances. GitHub. Retrieved October 2, 2025, from https://github.com/chneau/go-taillard/tree/master/pfsp/instances\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
